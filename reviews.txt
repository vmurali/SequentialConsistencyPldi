===========================================================================
                            popl15 Review #99A
                     Updated 19 Aug 2014 9:27:37pm EDT
---------------------------------------------------------------------------
   Paper #99: Modular Deductive Verification of Multiprocessor Hardware
              Designs
---------------------------------------------------------------------------

                      Overall merit: B. OK paper, but I will not champion
                                        it
                         Confidence: Y. I am knowledgeable in this area,
                                        but not an expert

                   ===== Comments for the Authors =====

This paper was a pleasure to read, as I found it was really well
written, and I enjoyed its theme. However I'm not completely
enthusiastic about it, for several reasons:

1. One of the main result of the paper is the "formal proof that when
an atomic memory is connected to n speculative processors, the system
as a whole is sequentially consistent" sadly, I couldn't quite a sense
of why that result is important. I appreciate the care taken in making
the proof (and thus the Coq development) modular, but I wonder why we
should focus on this particular result.

   On a related note, I couldn't quite understand why the "rather
surprising" result claimed on page 2, col 2, is indeed suprising.

2. I find that weak memory concerns have been relatively glossed over,
in two ways:
   a. the paper assumes store atomicity, but does not really discuss
to what extent the proofs are easily amenable to relaxing this
feature. I can see the following remark, but I don't find it
convincing at all:

     (page 1, col 1) "store atomicity [...], a property that all
reasonable memories have in common":
       - if by store atomicity you mean forbidding IRIW+dependencies,
viz, assuming that x and y hold 0 initially:

         W x 1 | R x | W y 1 | R y
               | dep |       | dep
               | R y |       | R x

         can the second thread read 1 in x, and 0 in y, whilst the
fourth thread reads 1 in y and 0 in x?
         Power and ARM allow this behaviour; should we consider these
architectures unreasonable?

       - you might even mean forbidding store buffering idioms, viz:

         W x 1 | W y 1
         R y   | R x

         can the two reads read 0?
         x86, Power and ARM allow this behaviour; should we consider
these architectures unreasonable?

   b. the paper claims several times that its methodology should be
easily amenable to weak memory, but without much justification:

      (page 2, col 1) "we conjecture that the methodology generalizes
to other popular memory models": I must say that assuming store
atomicity makes the generalization not obvious at all. What are the
arguments in favour of your conjecture?

      (page 2, col 2) "We believe such a memory is also the correct
abstraction for implementing relaxed memory models": Why is that?

    Moreover, these two statements seem at odds with the following one:

    (page 11, col 2) "One can potentially adjust our processor model
[...]. The details are not obvious, however."

  c. the related work about weak memory is quite off:

     (page 11, col 2) "Axioms regarding relaxed memory models have
also been proposed through analysis of empirically observed behavior
of certain "litmus tests" [17,24]." This is wrong for two reasons:

        i. [24] presents an (extension of an) operational model, thus
should not be listed in this sentence that concerns axiomatic models
-- moreover [24] is an extension of [23], so when referring to the
Power model of Sarkar et al, one really should cite [23,24] together;

        ii. "analysis of empirically observed behavior of certain
litmus tests" is really Alglave and Maranget's line of work (see e.g.
[1,2] and Alglave et al at CAV 10, TACAS 11, CAV 11 and FMSD 12);
their testing tool suite and analysis methods have contributed to
[17,23,24]; but the sentence as is leaves them completely out of the
scope.

      (page 11, col 2) "some work in providing operational semantics
that describe the observed behavior of real hardware [23]": does that
mean that all the other works on Power (e.g. [2,17,24] or Alglave et
al at CAV 10, CAV 11 and FMSD 12) do not target "real hardware"? This
seems strange as [23] targets Power just as well as all these other
works. Moreover, what about all the works on x86 (e.g. [25] and Owens
et al at TPHOLs 09)? Is that not real hardware?

  Finally, I don't quite understand what this paragraph about weak
memory is supposed to achieve; the beginning of the paragraph lets me
think that you're listing a bunch of works that you could use to
extend your method, but it doesn't seem to be the case at all.

3. There are several statements that I find slightly over-claiming, or
unjustified:

   (page 1, col 1) "Hardware designers [...] have already become some
of the most serious real-world adopters of formal methods": do you
have some data to back this up?

   (page 1, col 2) "the formalism of labeled transition systems [...]
turns out to be exactly the right way of capturing contracts on
interaction between hardware components": I couldn't find what
justifies this claim in the paper

   (page 8, col 2) "We believe that other invalidation-based protocols
with inclusive caches [...] also satisfy our invariants and lemmas":
why is that?

   (page 11, col 1) "We have demonstrated a high-performance
implementation of SC": where are the experimental data that justify
this claim?

More details:

page 1, col 1:

independently of the processor: what does this mean?

an atomic memory is connected to n speculative processors: how
realistic is that?

real-world adopters of formal methods: do you have some data to back this up?

page 1, col 2:

deductive approach: what is this? Also where did you say that your
approach was deductive before?

well-known in process-calculus circles: I'm not sure why it's
necessary to say that here; also I suspect that LTS are know in other
circles too

to be exactly the right way: do you have some data to back this up?

page 2, col 1:

conjecture that the methodology [...]: do you have some arguments to
back this up?

multiple processors executing each instruction atomically thus
implementing sequential consistency: the causality link expressed by
"thus" is not clear to me

page 2, col 2:

believe such a memory is also the correct abstraction [...]: why is that?

shown a (rather surprising) [...]: why is that suprising?

decoupled shared-memory systems: what is this?

page 3, col 2:

forcing traces in the two systems to match exactly: is that not too strong?

page 4, col 1:

We need know: "to" missing

page 4, col 2:

Realistic hardware systems do not implement the monolithic SC model of
Figure 3 directly: they do not implement SC at all, do they?

decoupled processor: what is this?

page 8, col 1:

believe that other invalidation-based protocols with inclusive caches
[...]: why is that?

page 10, col 1:

Lemma 3, 4, 5, 6: I think I would gather these results altogether
rather than aligning them like that; at least put some words in
between the lemmas

believe to be the key insight for proving any cache-coherence
protocol: why do you believe this? would you explain a bit more?

page 11, col 1:

a high-performance implementation of SC: do you have some data to back this up?

page 11, col 2:

CRF: what is this?

===========================================================================
                            popl15 Review #99B
                     Updated 22 Aug 2014 1:36:20pm EDT
---------------------------------------------------------------------------
   Paper #99: Modular Deductive Verification of Multiprocessor Hardware
              Designs
---------------------------------------------------------------------------

                      Overall merit: B. OK paper, but I will not champion
                                        it
                         Confidence: Y. I am knowledgeable in this area,
                                        but not an expert

                   ===== Comments for the Authors =====

The main contribution of this paper is a an end-to-end proof, in a
single verification system, that a hardware microarchitecture hooked
up to a multiprocessor memory sub-system implements sequential
consistency.  There are a lot of papers on *full* verification of
microarchitecture and cache-coherence protocol but I would tend to
agree with the authors that these various proofs have not been put
together in one formal system.

There are two negative aspects of this paper:
1. There does not appear to be any novelty in the central proof
technique of modular refinement of labeled transition systems.
2. As far as I can tell, refinement is done down to a level that is
still very far from any realistic hardware implementation.  I would be
more supportive of this paper if the authors had done the extra work
of hooking up their work with a hardware synthesis tool (such as
BlueSpec which the authors are aware of) and tried to estimate how far
off they are compared to a realistic hardware implementation. I do
understand this is a lot of work though.

The paper is well-written.

The authors are aware of some of the related work done in the
CAV/FMCAD (essentially the hardware/protocol-verification community)
but not all.  I include below a few more references to full
verification (as opposed to bug-finding with finite parameters) done
is systems such as PVS and Cadence SMV.  More references would be
available from these papers.

Kenneth L. McMillan: Parameterized Verification of the FLASH Cache
Coherence Protocol by Compositional Model Checking. CHARME 2001:
179-195

Ranjit Jhala, Kenneth L. McMillan: Microarchitecture Verification by
Compositional Model Checking. CAV 2001: 396-410

http://wimhesselink.nl/mechver/lazyCaching/whh324a.pdf

http://dl.acm.org/citation.cfm?id=1063431

===========================================================================
                            popl15 Review #99C
                    Updated 26 Aug 2014 12:48:32pm EDT
---------------------------------------------------------------------------
   Paper #99: Modular Deductive Verification of Multiprocessor Hardware
              Designs
---------------------------------------------------------------------------

                      Overall merit: C. Weak paper, though I will not fight
                                        strongly against it
                         Confidence: X. I am an expert in this area

                   ===== Comments for the Authors =====

This paper presents a proof of a MSI-based cache coherence protocol
between any number of speculative, branch predicting processors and a
memory with an arbitrary tree-shaped cache hierarchy. The proof
establishes that the whole system simulates a sequentially consistent
one. The proof is modular in that the simulation relation is
established by successive, independent refinements of the processor
subsystems and the memory subsystem.

Thanks to the clever design and decomposition of the proof, and
although the end system under study is fairly complex, the individual
proof steps are comparatively easy-to-follow and natural. Moreover,
each component (either processor or memory) may be refined further
into more optimised versions of themselves. The modularity of the
proof means that it will then be enough to prove that the new version
refines the old one for the whole proof to carry over to the new
composite system. Previous proofs of high-level implementations of
MSI-based protocols usually lack these features, e.g. proceed by
explicit model-checking on a concrete implementation where the number
of processors, cache lines, etc., is fixed. This new proof is a
significant improvement in that respect: the proof easily scales to
arbitrary architectures of the same shape, and to many variations on
the same design.

Overall, this is a nice piece of work, and the authors did a good job
at presenting a non-trivial proof, helped by the clear structure of
the proof itself, of a non-trivial distributed system. However, I do
not think that the results are strong enough or that the claims of
generality have been sufficiently backed by the authors to warrant
acceptance at the POPL conference. For this to be the case, I would
expect the following points to be addressed.

- The system studied by the author, even with the full set of features
  (branch prediction and read speculation), sits at a much higher
  level of abstraction than actual hardware designs. Despite many
  occurrences in the paper that this system is realistic, no evidence
  is cited to back that claim, which does not seem self-evident to
  me. Famously, modern microprocessors do not implement sequential
  consistency. Moreover, it is not said which silicon-based
  architecture the final system proved by the authors is supposed to
  emulate. The authors mention that it is a "transliteration of a
  realistic algorithm implemented in the Bluespec hardware description
  language", but do not provide a reference as to which algorithm that
  is (only a reference to the specification of said hardware language
  is given).

  The positive flipside of this higher level of abstraction is that
  the ideas present in this work should apply equally well to
  cache-coherence protocols implemented in software.

- The choices made by the authors for the semantics and specific
  aspects of the implementation are not justified enough.

  While the ISA does seem general, does it subsume the ISAs of
  well-known architectures? For instance, there is no support for
  CISC-like instructions such indirect addressing, or for memory
  barriers, special reads, and special writes.

  Similarly, why focus on MSI and directory-based cache-coherence
  protocols?

  The simulation results focus on termination properties, but it is
  not justified why. Moreover, this choice can be a bit surprising
  given that the execution of microprocessors never "terminates".


- The claim that the main proof is easily adapted to various other
  coherence protocols is not sufficiently backed by the authors.

  Although one can imagine that the proof applies to many variations
  around the design verified by the authors (and indeed for any
  architecture that fits the hierarchical shape of caches and
  processors studied in this paper), it is not at all obvious that the
  proof can be applied to other designs without significant
  re-engineering.

  Examples of alternative designs include:

  * Different invalidation strategies, e.g., MOSI/MESI/MOESI, Firefly,
    etc.

  * Snooping protocols instead of directory-based

  * Distributed directories instead of a single directory

  A compelling argument would have been for the authors to adapt their
  proof to some of these variations to test their claim themselves.


- The authors stress the benefits of using LTSs, yet their models
  often mix labelled transitions with explicit encoding of buffers
  into the state. Perhaps the models would benefit from a more unified
  design, for instance using asynchronous state transition systems.


Detailed comments
-----------------

- The use of underlines instead of italics for emphasis is distracting.

- Figure captions are sentences and thus should end in full stops.

p1c1: "Such a system implements memory models like sequential
consistency (SC) [15], Total Store Order (TSO), and Relaxed Memory
Order (RMO) [29]"

-> Please give references, for each class of memory model, of
   implementations that follow them (eg, x86 for TSO). Please give a
   reference for TSO.

p1c2: please give a reference for FSMs.

"For example, if we change the timing of an adder so that it takes 2
clock cycles instead of 1, the whole system is likely to break."

-> I think this sentence is missing some context.

Figure 1: I could not find in the text what the two vertically-stacked
rectangles above each Proc_i (and below each L_1) represent.

p2c1: "we conjecture that the methodology generalizes to other popular
memory models."

-> It is not clear on what grounds this conjecture rests. The claim
   that the proof should extend to weak memory models is present
   several times in the paper, but weak memory models are so vastly
   different that it is highly non-obvious if one could also reason in
   a modular way using the same techniques as in this paper. In fact,
   some suggest (Herding cats, Alglave et al., TOPLAS'14) that
   operational semantics are inadequate to study such systems.

"they work for any reorder buffer satisfying a simple semantic
condition."

-> Please provide an intuition of what that condition is, or at least
   a forward reference.

p2c2: "Our current framework establishes theorems of the form 'if
system A has a run with some particular observable behavior, then
system B also has a run with the same behavior.'"

-> Please motivate this better. Why is the other direction omitted?

"As a side effect, we have shown a (rather surprising) architec-
tural result about the semantics of the interface between processor
and memory system. One can establish a sequentially consistent
system even if the buffers between the memory system and the pro-
cessor do not preserve message order."

-> Given that all of these buffers are actually one-place buffers, I
   do not think this result is very surprising.

p3c1: "Definition 3. The n-repetition of A, written An , is a derived
LTS. Where A's states and labels [...]"

-> ... is a derived LTS, where ...

"The whole system halts whenever one of the components halts."

-> This seems unusual. I would expect such a definition for
   "crashing", not merely halting.

p3c2: "Where A and B" -> When A and B

In the LTS of A + B, there is no rule for transitions of the form
 (a) -->^l_A (H)
(i.e., labelled transitions resulting in halting). Are they implicitly
disallowed?

Section 2.3 is titled "A few useful lemmas", yet contains "Theorem"
items.

p4c1: Figure 3: in most places, s and pc are ordered as "s, pc" (eg,
\theta(i) = (s,pc), dec(s,pc), ...), but the result of "exec" is of
the form "(pc, s)", i.e., the pair is inverted.

p5c2: "The associated operations are: \phi, the state of an empty
buffer." -> this first item is not an operation. Please rephrase.

p6c2: "This step mimics the mechanism implemented in most modern-day
processors" -> Please provide a reference

p7c1: "(where the latter is one of our preliminary results about
n-repetition)" -> this seems redundant.

p8c2: "denote the number of transitions that occurred before reaching
the specified state." -> is it rather the number of non-epsilon
transitions?

"We believe that [...]; we omit the discussion [...]"

-> The second part of this sentence suggests that other protocols have
   also been proven, but the first part suggests that this is not the
   case. Which is it?

Please pull Def. 8 above Lemma 1, and Def. 9 above Lemma 2.

Lemma 4: "The state of an address" -> The coherence state of an
address

Lemma 5: "The state of a cache" -> this has not been defined.

It is unclear to me what the difference between Lemmas 4 and 5 is.

Figure 11: To what scenario does this diagram correspond? Perhaps
annotate the transitions with the names of the reduction rules that
they embody?

p11c1: It is unclear to me to whom Section 9 is targeted. The points
1. and 2. are possible optimisation on top of the authors' design,
while 3. seems to be future work for the authors.

"Incorporating this solution will require a very small change in our
processor interface"

-> A good demonstration of the good design of the proof would be to
   implement this solution.

"The formal proof of why this scheme works is beyond the scope of this
paper."

-> This seems to contradict the claim that the solution presented in
   this paper is easy to adapt to other protocols.

"A more aggressive solution to maintaining the strict load-store
orderings defined by SC is to change the memory model itself."

-> Please rephrase: if you are changing the memory model and
   abandoning SC, then it is not a solution to maintaining SC.

"However, neither proof establishes that the protocol is store
atomic. Rather, they show that Cachet obeys the CRF memory model,
which is not restricted to store-atomic behavior."

-> Please rephrase: if the protocol does not in fact satisfy store
   atomicity, then why should they prove that it does?

===========================================================================
                            popl15 Review #99D
                     Updated 5 Sep 2014 4:58:45pm EDT
---------------------------------------------------------------------------
   Paper #99: Modular Deductive Verification of Multiprocessor Hardware
              Designs
---------------------------------------------------------------------------

                      Overall merit: C. Weak paper, though I will not fight
                                        strongly against it
                         Confidence: X. I am an expert in this area

                   ===== Comments for the Authors =====

This paper describes a Coq refinement proof between a LTS system that
describes a basic SC interleaving semantics and a low level LTS based
on a cache hierarchy and speculating instruction processing.

This is an interesting paper and a nice work but I have two major concerns
 1) I do not understand fully the final theorem. I would expect such
an optimized architecture to not fulfill a SC spec. A race freedom
hypothesis is certainly hidden somewhere but not in a very explicit
way. This is certainly related to the discussion in section 9 but I
found it confusing.
 2) the overall proof effort does not seems extremely high for POPL criteria

I believe such a work could be of interest for a theorem proving
conference if the author make more explicit the assumptions they made
in their final theorem.

